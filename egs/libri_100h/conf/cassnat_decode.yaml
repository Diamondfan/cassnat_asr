vocab_file: data/dict/vocab_wp.txt
global_cmvn: data/fbank/cmvn_sp.ark
use_cmvn: True
use_BERT_tokenizer: False
tokenizer: "data/dict/bpemodel_unigram_1024.model"
bert_name: "bert-base-uncased"
bert_path: "/data/ruchao/workdir/language_model/bert/" 

#model configuration
model_type: "conformer"
input_size: 80
N_enc: 12
N_extra: 1
N_self_dec: 5 #3
N_mix_dec: 2 #4
d_model: 512 #256
d_ff: 2048
n_head: 8 #4
dropout: 0
use_mlm: False
apply_mask: False
use_mask_embed: True

#conformer related conf
use_conv_enc: True
share_ff: False
d_encff: 1024
d_decff: 1024 #2048
pos_type: "relative"
enc_max_relative_len: 20
enc_kernel_size: 31
use_conv_dec: True
dec_max_relative_len: 8
dec_kernel_size: 3

n_features: 80
vocab_size: 4990
left_ctx: 0
right_ctx: 0
skip_frame: 1
padding_idx: 0
text_padding_idx: 0

use_gpu: True
max_len: 5000
filter_max: 5000
filter_min: 0

#beam_decode
decode_type: 'esa'
max_decode_ratio: 0
beam_width: 1
ctc_beam: 1 #20
ctc_pruning: 0 #30
ctc_lp: 0 #2
ctc_lm_weight: 0.1 #used to load lm for ranking ESA
length_penalty: 0
T: 1.0

#nat related conf
use_trigger: True
src_trigger: False
use_unimask: False
left_trigger: 1
right_trigger: 1
use_best_path: False
sample_num: 16 #50
threshold: 0.9

test_hitrate: False
save_embedding: False
print_utt2diff: False
